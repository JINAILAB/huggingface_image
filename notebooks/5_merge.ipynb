{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 상위 폴더로 이동\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data_presets import ClassificationPresetEval\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForImageClassification\n",
    "from image_utils import run_model, get_metric_from_df, plot_rocauc_from_df, plot_cm_from_df, create_hook, get_embedding_layer\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\n",
    "    \"./cifar100_facebook_convnext-small-224\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dirs = []\n",
    "for folder in folder_paths:\n",
    "    hf_dirs.extend(glob.glob(f\"{folder}/*/best.hf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0247/best.hf',\n",
       " './cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0327/best.hf',\n",
       " './cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0444/best.hf',\n",
       " './cifar100_facebook_convnext-small-224/convnext-small-224_merge/best.hf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 3개의 모델을 평균합니다.\n",
      "모델 로딩 중 (1/3): ./cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0247/best.hf/model.safetensors\n",
      "모델 로딩 중 (2/3): ./cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0327/best.hf/model.safetensors\n",
      "모델 로딩 중 (3/3): ./cifar100_facebook_convnext-small-224/convnext-small-224_20241021_0444/best.hf/model.safetensors\n",
      "새로운 모델이 'cifar100_facebook_convnext-small-224/best.hf/model.safetensors'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 모델 파일 경로 리스트 생성\n",
    "hf_dirs = []\n",
    "for folder in folder_paths:\n",
    "    hf_dirs.extend(glob.glob(f\"{folder}/*/best.hf/model.safetensors\"))\n",
    "\n",
    "# 합산된 파라미터를 저장할 딕셔너리 초기화\n",
    "summed_params = {}\n",
    "\n",
    "# 모델의 수 계산\n",
    "num_models = len(hf_dirs)\n",
    "print(f\"총 {num_models}개의 모델을 평균합니다.\")\n",
    "\n",
    "# 각 모델 파일에서 파라미터 로드 및 합산\n",
    "for idx, path in enumerate(hf_dirs):\n",
    "    print(f\"모델 로딩 중 ({idx+1}/{num_models}): {path}\")\n",
    "    params = {}\n",
    "    with safe_open(path, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            params[key] = f.get_tensor(key)\n",
    "    if idx == 0:\n",
    "        # 첫 번째 모델의 파라미터로 초기화\n",
    "        for key in params.keys():\n",
    "            summed_params[key] = params[key].clone()\n",
    "    else:\n",
    "        # 이후 모델의 파라미터를 합산\n",
    "        for key in params.keys():\n",
    "            summed_params[key] += params[key]\n",
    "\n",
    "# 합산된 파라미터를 모델 수로 나누어 평균 계산\n",
    "for key in summed_params.keys():\n",
    "    summed_params[key] /= num_models\n",
    "\n",
    "# 첫 번째 모델의 'best.hf' 폴더를 복사하여 새로운 폴더 생성\n",
    "best_hf_dir = os.path.dirname(hf_dirs[0])\n",
    "dest_folder = 'cifar100_facebook_convnext-small-224/best.hf'\n",
    "\n",
    "# 기존 폴더가 있으면 삭제\n",
    "if os.path.exists(dest_folder):\n",
    "    shutil.rmtree(dest_folder)\n",
    "\n",
    "# 폴더 복사\n",
    "shutil.copytree(best_hf_dir, dest_folder)\n",
    "\n",
    "# 평균된 파라미터를 새로운 safetensors 파일로 저장\n",
    "save_file(\n",
    "    summed_params,\n",
    "    os.path.join(dest_folder, 'model.safetensors'),\n",
    "    metadata={\"format\": \"pt\"}  # 메타데이터 추가\n",
    ")\n",
    "print(f\"새로운 모델이 '{os.path.join(dest_folder, 'model.safetensors')}'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config parameter 설정\n",
    "config = {\n",
    "    \"model_dir\" : '/workspace/model/hugginface_image_classifcation/cifar100_facebook_convnext-small-224/best.hf',\n",
    "    \"dataset_dir\" : '/workspace/model/hugginface_image_classifcation/data/hfdataset/test',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(config['dataset_dir'])\n",
    "labels = dataset['test'].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "    \n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "        config['model_dir'],\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "        ignore_mismatched_sizes = True,\n",
    "    )\n",
    "\n",
    "def preprocess_valid(batch, valid_transforms):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    if \"image\" in batch:\n",
    "        batch[\"pixel_values\"] = [\n",
    "            valid_transforms(image.convert(\"RGB\")) for image in batch[\"image\"]\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "valid_transform = ClassificationPresetEval(\n",
    "            crop_size=224,\n",
    "            resize_size=256,\n",
    "            interpolation=InterpolationMode.BILINEAR,\n",
    "            use_v2=True,\n",
    "        )\n",
    "\n",
    "valid_ds = dataset['test']\n",
    "valid_ds.set_transform(lambda batch: preprocess_valid(batch, valid_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "valid_df = run_model(model, valid_ds, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.873,\n",
       " 'top2_accuracy': 0.9491,\n",
       " 'precision': 0.873,\n",
       " 'recall': 0.873,\n",
       " 'f1_score': 0.873,\n",
       " 'roc_auc': 0.9987518367676768,\n",
       " 'specificity': 0.9987171717171717}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metric_from_df(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
